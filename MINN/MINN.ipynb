{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network for Wiener-Hopf kernel factorization\n",
    "# Author: Liang Sicong\n",
    "# Date: November 13, 2023\n",
    "# Reference: https://github.com/maziarraissi/PINNs\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from config_gpu import config_gpu\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as scio\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for Wiener-Hopf kernel factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MINN_init(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus,\n",
    "                x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg,\n",
    "                x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc,x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,\n",
    "                 Rm, Rn, Rl, depth, activ = \"tanh\", BN = False, \n",
    "                 w_init = \"glorot_normal\", b_init = \"zeros\", \n",
    "                 lr = 1e-3, opt = \"Adam\", w_k = 1., w_cr = 1., w_z = 1., w_dense = 0.01,\n",
    "                 f_mntr = 10, r_seed = 1234):\n",
    "        \n",
    "        # initialize the configuration\n",
    "        super().__init__()\n",
    "        self.r_seed = r_seed\n",
    "        self.random_seed(seed = r_seed)\n",
    "        self.data_type  = tf.float32\n",
    "        self.Rm     = Rm       # input dimension\n",
    "        self.Rn     = Rn       # output dimension\n",
    "        self.Rl     = Rl       # internal dimension width\n",
    "        self.depth  = depth    # (# of hidden layers) + output layer\n",
    "        self.activ  = activ    # activation function\n",
    "        self.BN     = BN       # BatchNorm? \n",
    "        self.w_init = w_init   # initial weight\n",
    "        self.b_init = b_init   # initial bias\n",
    "        self.lr     = lr       # learning rate\n",
    "        self.opt    = opt      # name of your optimizer (\"SGD\", \"RMSprop\", \"Adam\", etc.)\n",
    "        self.w_k    = w_k      # weight for R+ loss\n",
    "        self.w_cr  = w_cr     # weight for R- loss\n",
    "        self.w_z    = w_z      # weight for R_junction loss\n",
    "        self.w_dense = w_dense\n",
    "        self.f_mntr = f_mntr   # monitoring frequency\n",
    "        \n",
    "        # input-output pair\n",
    "        self.x_plus = x_plus;  self.y_plus = y_plus ;  self.prt_plus = prt_plus;  self.pit_plus = pit_plus \n",
    "        self.qrt_plus = qrt_plus;  self.qit_plus = qit_plus;self.rrt_plus = rrt_plus;  self.rit_plus = rit_plus\n",
    "        self.srt_plus = srt_plus;  self.sit_plus = sit_plus\n",
    "        self.x_neg = x_neg;  self.y_neg = y_neg ;  self.prt_neg = prt_neg;  self.pit_neg = pit_neg \n",
    "        self.qrt_neg = qrt_neg;  self.qit_neg = qit_neg;self.rrt_neg = rrt_neg;  self.rit_neg = rit_neg\n",
    "        self.srt_neg = srt_neg;  self.sit_neg = sit_neg\n",
    "        self.x_junc = x_junc;  self.y_junc = y_junc ;  self.prt_junc = prt_junc;  self.pit_junc = pit_junc \n",
    "        self.qrt_junc = qrt_junc;  self.qit_junc = qit_junc;self.rrt_junc = rrt_junc;  self.rit_junc = rit_junc\n",
    "        self.srt_junc = srt_junc;  self.sit_junc = sit_junc\n",
    "        self.x_circle_plus = x_circle_plus;  self.y_circle_plus = y_circle_plus ;  self.x_circle_neg = x_circle_neg;  self.y_circle_neg = y_circle_neg ;\n",
    "\n",
    "        \n",
    "        # call\n",
    "        self.dnn = self.dnn_init(Rm, Rn, Rl, depth)\n",
    "        self.dnn.layers[-6].trainable=False\n",
    "        self.dnn.layers[-5].trainable=False\n",
    "        self.dnn.layers[-4].trainable=False\n",
    "\n",
    "        self.params = self.dnn.trainable_variables\n",
    "        self.optimizer = self.opt_alg(self.lr, self.opt)\n",
    "\n",
    "        # track loss\n",
    "        self.ep_log = []\n",
    "        self.loss_log = []\n",
    "        \n",
    "        print(\"\\n************************************************************\")\n",
    "        print(\"****************     MAIN PROGRAM START     ****************\")\n",
    "        print(\"************************************************************\")\n",
    "        print(\">>>>> start time:\", datetime.datetime.now())\n",
    "        print(\">>>>> configuration;\")\n",
    "        print(\"         dtype        :\", self.data_type)\n",
    "        print(\"         activ func   :\", self.activ)\n",
    "        print(\"         weight init  :\", self.w_init)\n",
    "        print(\"         learning rate:\", self.lr)\n",
    "        print(\"         optimizer    :\", self.opt)\n",
    "        print(\"         summary      :\", self.dnn.summary())\n",
    "        \n",
    "    def random_seed(self, seed = 1234):\n",
    "        os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        \n",
    "    def dnn_init(self, Rm, Rn, Rl, depth):\n",
    "        # network configuration (N: Rm -> Rn (Rm -> Rl -> ... -> Rl -> Rn))\n",
    "        network = tf.keras.Sequential()\n",
    "        network.add(tf.keras.layers.InputLayer(Rm))\n",
    "#         network.add(tf.keras.layers.Lambda(lambda x: 2. * (x - self.lb) / (self.ub - self.lb) - 1.))\n",
    "        \n",
    "        if self.BN == True:   # False by default\n",
    "            for l in range(depth - 1):\n",
    "                network.add(tf.keras.layers.Dense(Rl, activation = self.activ, use_bias = False,\n",
    "                                                  kernel_initializer = self.w_init, bias_initializer = self.b_init, \n",
    "                                                  kernel_regularizer = None, bias_regularizer = None, \n",
    "                                                  activity_regularizer = None, kernel_constraint = None, bias_constraint = None))\n",
    "                network.add(tf.keras.layers.BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001, \n",
    "                                                               center = True, scale = True,\n",
    "                                                               beta_initializer = \"zeros\", gamma_initializer = \"ones\",\n",
    "                                                               moving_mean_initializer = \"zeros\",\n",
    "                                                               moving_variance_initializer = \"ones\", \n",
    "                                                               beta_regularizer = None, gamma_regularizer = None, \n",
    "                                                               beta_constraint  = None, gamma_constraint  = None))\n",
    "            \n",
    "        else:   # False by default\n",
    "            for l in range(depth - 1):\n",
    "#              for l in range(depth - 1):\n",
    "                if l==3:\n",
    "                    RR=Rl*2\n",
    "                else:\n",
    "                    RR=Rl\n",
    "                network.add(tf.keras.layers.Dense(RR, activation = self.activ, use_bias = True,\n",
    "                                                  kernel_initializer = self.w_init, bias_initializer = self.b_init, \n",
    "                                                  kernel_regularizer = None, bias_regularizer = None, \n",
    "                                                  activity_regularizer = None, kernel_constraint = None, bias_constraint = None))\n",
    "        network.add(tf.keras.layers.Dense(Rn))\n",
    "        return network\n",
    "     \n",
    "    def opt_alg(self, lr, opt):\n",
    "        if   opt == \"SGD\":\n",
    "            optimizer = tf.keras.optimizers.SGD(learning_rate = lr, momentum = 0.0, nesterov = False)\n",
    "        elif opt == \"RMSprop\":\n",
    "            optimizer = tf.keras.optimizers.RMSprop(learning_rate = lr, rho = 0.9, momentum = 0.0, centered = False)\n",
    "        elif opt == \"Adam\":\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate = lr, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
    "        elif opt == \"Adamax\":\n",
    "            optimizer = tf.keras.optimizers.Adamax(learning_rate = lr, beta_1 = 0.9, beta_2 = 0.999)\n",
    "        elif opt == \"Nadam\":\n",
    "            optimizer = tf.keras.optimizers.Nadam(learning_rate = lr, beta_1 = 0.9, beta_2 = 0.999)\n",
    "        else:\n",
    "            raise Exception(\">>>>> Exception: optimizer not specified correctly\")\n",
    "            \n",
    "        return optimizer\n",
    "    \n",
    "    def PDEk(self, x, y):\n",
    "        x = tf.convert_to_tensor(x, dtype = self.data_type)\n",
    "        y = tf.convert_to_tensor(y, dtype = self.data_type)\n",
    "\n",
    "        with tf.GradientTape(persistent = True) as tp:\n",
    "            tp.watch(x)\n",
    "            tp.watch(y)\n",
    "            \n",
    "            uu = self.dnn(tf.concat([x, y], 1))\n",
    "            pr=uu[:,0:1]\n",
    "            pi=uu[:,1:2]\n",
    "            qr=uu[:,2:3]\n",
    "            qi=uu[:,3:4]\n",
    "            rr=uu[:,4:5]\n",
    "            ri=uu[:,5:6]\n",
    "            sr=uu[:,6:7]\n",
    "            si=uu[:,7:8]\n",
    "        del tp\n",
    "        return pr,pi,qr,qi,rr,ri,sr,si\n",
    "\n",
    "    ########## kr+i*ki=(a+bi)*(c+di)+(e+fi)*(g+hi)\n",
    "    def getri(self,a,b,c,d,e,f,g,h):\n",
    "        kr=a*c-b*d+e*g-f*h\n",
    "        ki=a*d+b*c+e*h+f*g\n",
    "        \n",
    "        return kr,ki\n",
    "    \n",
    "    ########## p/g_11(a)\n",
    "    def getp(self,w1,w2):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        k=tf.complex([5.0],[0.01])\n",
    "        gamma=tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        z=-gamma/2*0+1\n",
    "        xr=tf.compat.v1.real(z)\n",
    "        xi=tf.compat.v1.imag(z)\n",
    "        return xr,xi  \n",
    "    \n",
    "    ########## q/g_12(a)\n",
    "    def getq(self,w1,w2):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        k=tf.complex([5.0],[0.01])\n",
    "        gamma=tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        j0=tf.complex([0.0],[1.0])\n",
    "        a=tf.complex([0.0],[0.0])\n",
    "        h=tf.complex([2.0],[0.0])\n",
    "#         gamma_plus=tf.sqrt(k+x)\n",
    "        gammaj=j0*tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        gamma_neg=tf.sqrt(k-x)\n",
    "        gamma_plus=gammaj/gamma_neg\n",
    "        z=gamma_neg/gamma_plus*tf.exp(-h*gamma)\n",
    "        xr=tf.compat.v1.real(z)\n",
    "        xi=tf.compat.v1.imag(z)\n",
    "        return xr,xi \n",
    "    \n",
    "    ########## r/g_21(a)\n",
    "    def getr(self,w1,w2):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        k=tf.complex([5.0],[0.01])\n",
    "        gamma=tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        j0=tf.complex([0.0],[1.0])\n",
    "        a=tf.complex([0.0],[0.0])\n",
    "        h=tf.complex([2.0],[0.0])\n",
    "        gammaj=j0*tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        gamma_neg=tf.sqrt(k-x)\n",
    "        gamma_plus=gammaj/gamma_neg\n",
    "        z=-gamma_plus/gamma_neg*tf.exp(-h*gamma)\n",
    "        xr=tf.compat.v1.real(z)\n",
    "        xi=tf.compat.v1.imag(z)\n",
    "        return xr,xi   \n",
    "    \n",
    "    ########## s/G_22(a)\n",
    "    def gets(self,w1,w2):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        k=tf.complex([5.0],[0.01])\n",
    "        gamma=tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        z=-gamma/2*0+1\n",
    "        xr=tf.compat.v1.real(z)\n",
    "        xi=tf.compat.v1.imag(z)\n",
    "        return xr,xi\n",
    "    \n",
    "    ########## beta_plus(a)\n",
    "    def get_bplus(self,w1,w2):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        k=tf.complex([5.0],[0.01])\n",
    "        j0=tf.complex([0.0],[1.0])\n",
    "\n",
    "        gammaj=j0*tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        gamma_neg=tf.sqrt(k-x)\n",
    "        gamma_plus=gammaj/gamma_neg\n",
    "\n",
    "        xr=tf.compat.v1.real(gamma_plus)\n",
    "        xi=tf.compat.v1.imag(gamma_plus)\n",
    "        return xr[0],xi[0]  \n",
    "    \n",
    "    ########## beta_neg(a)\n",
    "    def get_bneg(self,w1,w2):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        k=tf.complex([5.0],[0.01])\n",
    "        j0=tf.complex([0.0],[1.0])\n",
    "\n",
    "        gammaj=j0*tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        gamma_neg=tf.sqrt(k-x)\n",
    "        gamma_plus=gammaj/gamma_neg\n",
    "\n",
    "        xr=tf.compat.v1.real(gamma_neg)\n",
    "        xi=tf.compat.v1.imag(gamma_neg)\n",
    "        return xr[0],xi[0]  \n",
    "    \n",
    "    def get_polar(self,w1,w2):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        k=tf.complex([2.5],[0.0050])\n",
    "        a=w1+2.5\n",
    "        b=w2+0.0050\n",
    "        zr=a/(tf.square(a)+tf.square(b))\n",
    "        zi=-b/(tf.square(a)+tf.square(b))\n",
    "        return zr,zi\n",
    "    \n",
    "    ########## kr+i*ki=(a+bi)*(c+di)\n",
    "    def get_multiply(self,a,b,c,d):\n",
    "        kr=a*c-b*d\n",
    "        ki=a*d+b*c     \n",
    "        return kr,ki\n",
    "    \n",
    "    ########## P(a)\n",
    "    def get_PP(self,w1,w2):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        k=tf.complex([5.0],[0.01])\n",
    "        j0=tf.complex([0.0],[1.0])\n",
    "        c1=tf.complex([0.6445],[0.2606])# beta0/(2*pi*1i)/psi0   0.6445 + 0.2606i\n",
    "        c2=tf.complex([0.1464],[-0.0589])# -psi0/(2*pi*1i)  0.1464 - 0.0589i\n",
    "        gammaj=j0*tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        gamma_neg=tf.sqrt(k-x)\n",
    "        gamma_plus=gammaj/gamma_neg\n",
    "        vecp1=c1/gamma_plus\n",
    "        vecp2=c2*gamma_plus\n",
    "        vecp1r=tf.compat.v1.real(vecp1)\n",
    "        vecp1i=tf.compat.v1.imag(vecp1)\n",
    "        vecp2r=tf.compat.v1.real(vecp2)\n",
    "        vecp2i=tf.compat.v1.imag(vecp2)\n",
    "        \n",
    "        return vecp1r[0],vecp1i[0],vecp2r[0],vecp2i[0]\n",
    "    \n",
    "    ########## 2*2 matrix inversion\n",
    "    def get_inv(self,pr,pi,qr,qi,rr,ri,sr,si):\n",
    "        p=tf.complex([pr],[pi])\n",
    "        q=tf.complex([qr],[qi])\n",
    "        r=tf.complex([rr],[ri])\n",
    "        s=tf.complex([sr],[si])\n",
    "        det=p*s-q*r\n",
    "        invp=s/det\n",
    "        invq=-q/det\n",
    "        invr=-r/det\n",
    "        invs=p/det\n",
    "        invpr=tf.compat.v1.real(invp)\n",
    "        invpi=tf.compat.v1.imag(invp)     \n",
    "        invqr=tf.compat.v1.real(invq)\n",
    "        invqi=tf.compat.v1.imag(invq)   \n",
    "        invrr=tf.compat.v1.real(invr)\n",
    "        invri=tf.compat.v1.imag(invr)   \n",
    "        invsr=tf.compat.v1.real(invs)\n",
    "        invsi=tf.compat.v1.imag(invs)  \n",
    "        return invpr[0],invpi[0],invqr[0],invqi[0],invrr[0],invri[0],invsr[0],invsi[0]\n",
    "    \n",
    "    ########## U*exp(iax) analytic in the upper half-plane\n",
    "    def get_fexp_plus2(self,w1,w2,f1r,f1i,f2r,f2i,gg):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        f1=tf.complex([f1r],[f1i])\n",
    "        f2=tf.complex([f2r],[f2i])\n",
    "        j0=tf.complex([0.0],[1.0])\n",
    "        z0=tf.complex([gg],[0.0])\n",
    "        expf=tf.exp(j0*x*z0)\n",
    "        f1x=f1*expf\n",
    "        f2x=f2*expf\n",
    "        f1rx=tf.compat.v1.real(f1x)\n",
    "        f1ix=tf.compat.v1.imag(f1x)\n",
    "        f2rx=tf.compat.v1.real(f2x)\n",
    "        f2ix=tf.compat.v1.imag(f2x)\n",
    "        return f1rx[0],f1ix[0],f2rx[0],f2ix[0]\n",
    "    \n",
    "    ########## V*exp(iax) analytic in the lower half-plane\n",
    "    def get_fexp_neg2(self,w1,w2,f1r,f1i,f2r,f2i,gg):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        f1=tf.complex([f1r],[f1i])\n",
    "        f2=tf.complex([f2r],[f2i])\n",
    "        j0=tf.complex([0.0],[1.0])\n",
    "        z0=tf.complex([gg],[0.0])\n",
    "        expf=tf.exp(j0*x*z0)\n",
    "        f1x=f1*expf\n",
    "        f2x=f2*expf\n",
    "        f1rx=tf.compat.v1.real(f1x)\n",
    "        f1ix=tf.compat.v1.imag(f1x)\n",
    "        f2rx=tf.compat.v1.real(f2x)\n",
    "        f2ix=tf.compat.v1.imag(f2x)\n",
    "        return f1rx[0],f1ix[0],f2rx[0],f2ix[0]     \n",
    "    \n",
    "    ########## U1,U2 analytic in the upper half-plane\n",
    "    def get_fplus(self,w1,w2,pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "                       inv_kpr,inv_kpi,inv_kqr,inv_kqi,inv_krr,inv_kri,inv_ksr,inv_ksi,\\\n",
    "                       kvecp1r,kvecp1i,kvecp2r,kvecp2i,\\\n",
    "                       vecp1r,vecp1i,vecp2r,vecp2i):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        p=tf.complex([pr],[pi])\n",
    "        q=tf.complex([qr],[qi])\n",
    "        r=tf.complex([rr],[ri])\n",
    "        s=tf.complex([sr],[si])\n",
    "        pk=tf.complex([inv_kpr],[inv_kpi])\n",
    "        qk=tf.complex([inv_kqr],[inv_kqi])\n",
    "        rk=tf.complex([inv_krr],[inv_kri])\n",
    "        sk=tf.complex([inv_ksr],[inv_ksi])\n",
    "        PPK1=tf.complex([kvecp1r],[kvecp1i])\n",
    "        PPK2=tf.complex([kvecp2r],[kvecp2i])\n",
    "        PPA1=tf.complex([vecp1r],[vecp1i])\n",
    "        PPA2=tf.complex([vecp2r],[vecp2i])     \n",
    "        k0=tf.complex([2.5],[0.0050]) \n",
    "        k=tf.complex([5.0],[0.010]) \n",
    "        F1=(p*pk+q*rk)*PPK1+(p*qk+q*sk)*PPK2-PPA1\n",
    "        F2=(r*pk+s*rk)*PPK1+(r*qk+s*sk)*PPK2-PPA2\n",
    "        j0=tf.complex([0.0],[1.0])\n",
    "        gammaj=j0*tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        gamma_neg=tf.sqrt(k-x)\n",
    "        b_plus=gammaj/gamma_neg\n",
    "        F1A=F1/(x+k0)*b_plus\n",
    "        F2A=F2/(x+k0)/b_plus\n",
    "        f1r=tf.compat.v1.real(F1A)\n",
    "        f1i=tf.compat.v1.imag(F1A)\n",
    "        f2r=tf.compat.v1.real(F2A)\n",
    "        f2i=tf.compat.v1.imag(F2A)\n",
    "        return f1r[0],f1i[0],f2r[0],f2i[0]\n",
    "    \n",
    "    ########## V1,V2 analytic in the lower half-plane\n",
    "    def get_fneg(self,w1,w2,pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "                       inv_kpr,inv_kpi,inv_kqr,inv_kqi,inv_krr,inv_kri,inv_ksr,inv_ksi,\\\n",
    "                       kvecp1r,kvecp1i,kvecp2r,kvecp2i):\n",
    "        x=tf.complex([w1],[w2])\n",
    "        p=tf.complex([pr],[pi])\n",
    "        q=tf.complex([qr],[qi])\n",
    "        r=tf.complex([rr],[ri])\n",
    "        s=tf.complex([sr],[si])\n",
    "        pk=tf.complex([inv_kpr],[inv_kpi])\n",
    "        qk=tf.complex([inv_kqr],[inv_kqi])\n",
    "        rk=tf.complex([inv_krr],[inv_kri])\n",
    "        sk=tf.complex([inv_ksr],[inv_ksi])\n",
    "        PPK1=tf.complex([kvecp1r],[kvecp1i])\n",
    "        PPK2=tf.complex([kvecp2r],[kvecp2i])    \n",
    "        k0=tf.complex([2.5],[0.0050]) \n",
    "        k=tf.complex([5.0],[0.010]) \n",
    "        j0=tf.complex([0.0],[1.0])\n",
    "        gammaj=j0*tf.sqrt(tf.square(x)-tf.square(k))\n",
    "        b_neg=tf.sqrt(k-x)\n",
    "        gamma_neg=tf.sqrt(k-x)\n",
    "        gamma_plus=gammaj/gamma_neg\n",
    "        F1=(p*pk+q*rk)*PPK1+(p*qk+q*sk)*PPK2\n",
    "        F2=(r*pk+s*rk)*PPK1+(r*qk+s*sk)*PPK2\n",
    "        F1A=F1/(x+k0)/b_neg\n",
    "        F2A=F2/(x+k0)*b_neg\n",
    "        f1r=tf.compat.v1.real(F1A)\n",
    "        f1i=tf.compat.v1.imag(F1A)\n",
    "        f2r=tf.compat.v1.real(F2A)\n",
    "        f2i=tf.compat.v1.imag(F2A)\n",
    "        return f1r[0],f1i[0],f2r[0],f2i[0]\n",
    "\n",
    "    def PDE(self, x, y):\n",
    "        x = tf.convert_to_tensor(x, dtype = self.data_type)\n",
    "        y = tf.convert_to_tensor(y, dtype = self.data_type)\n",
    "\n",
    "        with tf.GradientTape(persistent = True) as tp:\n",
    "#         with tf.GradientTape(persistent = False) as tp:\n",
    "            tp.watch(x)\n",
    "            tp.watch(y)\n",
    "        \n",
    "            ########## G_{+}^{-1}\n",
    "            uu = self.dnn(tf.concat([x, y], 1)) # input: complex \\alpha, output: G_{+}^{-1}(\\alpha)\n",
    "            pr=uu[:,0:1]  # real part of g_11(p)\n",
    "            pi=uu[:,1:2]  # imag part of g_11(p)\n",
    "            qr=uu[:,2:3]  # real part of g_12(q)\n",
    "            qi=uu[:,3:4]  # imag part of g_12(q)\n",
    "            rr=uu[:,4:5]  # real part of g_21(r)\n",
    "            ri=uu[:,5:6]  # imag part of g_21(r)\n",
    "            sr=uu[:,6:7]  # real part of g_22(s)\n",
    "            si=uu[:,7:8]  # imag part of g_22(s)\n",
    "            br,bi=self.get_bplus(x,y) # beta_plus\n",
    "            nbr,nbi=self.get_bneg(x,y)  # beta_neg\n",
    "            qrx=(qr*br+qi*bi)/(br*br+bi*bi)  # q=\\hat{q}/beta_plus\n",
    "            qix=(-qr*bi+qi*br)/(br*br+bi*bi) # q=\\hat{q}/beta_plus\n",
    "            qr=qrx;qi=qix\n",
    "            rrx=rr*br-ri*bi                  # r=\\hat{q}*beta_plus\n",
    "            rix=rr*bi+br*ri                  # r=\\hat{q}*beta_plus\n",
    "            rr=rrx;ri=rix\n",
    "\n",
    "            ########## G\n",
    "            prt,pit=self.getp(x,y)   \n",
    "            qrt,qit=self.getq(x,y)\n",
    "            rrt,rit=self.getr(x,y)\n",
    "            srt,sit=self.gets(x,y)\n",
    "            prt=prt[0];pit=pit[0];qrt=qrt[0];qit=qit[0];\n",
    "            rrt=rrt[0];rit=rit[0];srt=srt[0];sit=sit[0]\n",
    "\n",
    "            ########## G_{-}= G_{+}^{-1}G\n",
    "            pr2,pi2= self.getri(pr,pi,prt,pit,qr,qi,rrt,rit)\n",
    "            qr2,qi2= self.getri(pr,pi,qrt,qit,qr,qi,srt,sit)\n",
    "            rr2,ri2= self.getri(rr,ri,prt,pit,sr,si,rrt,rit)\n",
    "            sr2,si2= self.getri(rr,ri,qrt,qit,sr,si,srt,sit)\n",
    "            \n",
    "            ########## Auto differentiation of G_{+}^{-1}\n",
    "            pr_x = tp.gradient(pr, x);pr_y = tp.gradient(pr, y)\n",
    "            pi_x = tp.gradient(pi, x);pi_y = tp.gradient(pi, y)\n",
    "            qr_x = tp.gradient(qr, x);qr_y = tp.gradient(qr, y)\n",
    "            qi_x = tp.gradient(qi, x);qi_y = tp.gradient(qi, y)\n",
    "            rr_x = tp.gradient(rr, x);rr_y = tp.gradient(rr, y)\n",
    "            ri_x = tp.gradient(ri, x);ri_y = tp.gradient(ri, y)\n",
    "            sr_x = tp.gradient(sr, x);sr_y = tp.gradient(sr, y)\n",
    "            si_x = tp.gradient(si, x);si_y = tp.gradient(si, y)\n",
    "\n",
    "            ########## Just neglect it\n",
    "            pr2_x = pr_x;pr2_y = pr_y\n",
    "            pi2_x = pi_x;pi2_y = pi_y\n",
    "            qr2_x = qr_x;qr2_y = qr_y\n",
    "            qi2_x = qi_x;qi2_y = qi_y\n",
    "            rr2_x = rr_x;rr2_y = rr_y\n",
    "            ri2_x = ri_x;ri2_y = ri_y    \n",
    "            sr2_x = sr_x;sr2_y = sr_y\n",
    "            si2_x = si_x;si2_y = si_y\n",
    "     \n",
    "        del tp\n",
    "        ########## Caucy-Riemann equations\n",
    "        gv1 = pr_x-pi_y;  gv2 = pr_y+pi_x # du/dx-dv/dy     positive Caucy-Riemann\n",
    "        gv3 = qr_x-qi_y;  gv4 = qr_y+qi_x # du/dx-dv/dy     positive Caucy-Riemann\n",
    "        gv5 = rr_x-ri_y;  gv6 = rr_y+ri_x # du/dx-dv/dy     positive Caucy-Riemann\n",
    "        gv7 = sr_x-si_y;  gv8 = sr_y+si_x # du/dx-dv/dy     positive Caucy-Riemann\n",
    "        gh1 = pr2_x-pi2_y;  gh2 = pr2_y+pi2_x # du/dx-dv/dy     positive Caucy-Riemann\n",
    "        gh3 = qr2_x-qi2_y;  gh4 = qr2_y+qi2_x # du/dx-dv/dy     positive Caucy-Riemann\n",
    "        gh5 = rr2_x-ri2_y;  gh6 = rr2_y+ri2_x # du/dx-dv/dy     positive Caucy-Riemann\n",
    "        gh7 = sr2_x-si2_y;  gh8 = sr2_y+si2_x # du/dx-dv/dy     positive Caucy-Riemann\n",
    "        return pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8\n",
    "    \n",
    "    ########## Caucy-Riemann equations\n",
    "    def get_jifen(self,a,b,c,d):\n",
    "        xr=a*c-b*d\n",
    "        xi=b*c+a*d\n",
    "        return xr,xi\n",
    "    \n",
    "    ########## L_CI and L_BC in the upper half-plane\n",
    "    ########## l_CI: Caucy integral loss\n",
    "    ########## l_BC: Boundary condition loss\n",
    "    def loss_circle_plus(self, x, y, prt,pit,qrt,qit,rrt,rit,srt,sit):\n",
    "        pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8 = self.PDE(x, y)  ### G(alpha)\n",
    "        xx_kminus=np.ones([1,1])*(-2.5)\n",
    "        yy_kminus=np.ones([1,1])*(-0.0050)\n",
    "        kpr,kpi,kqr,kqi,krr,kri,ksr,ksi,\\\n",
    "               kpr2,kpi2,kqr2,kqi2,krr2,kri2,ksr2,ksi2,\\\n",
    "               kgv1,kgv2,kgv3,kgv4,kgv5,kgv6,kgv7,kgv8,\\\n",
    "               kgh1,kgh2,kgh3,kgh4,kgh5,kgh6,kgh7,kgh8 = self.PDE(xx_kminus, yy_kminus) ###G+^-1(-k0)\n",
    "        kvecp1r,kvecp1i,kvecp2r,kvecp2i=self.get_PP(-2.5, -0.0050)   ### p(-k0)\n",
    "        inv_pr,inv_pi,inv_qr,inv_qi,inv_rr,inv_ri,inv_sr,inv_si=\\\n",
    "                                    self.get_inv(pr,pi,qr,qi,rr,ri,sr,si) ### G+(alpha)\n",
    "        ######################################################################\n",
    "        ########## l_CI: Caucy integral loss\n",
    "        N2=2000\n",
    "        NK=0\n",
    "        dx=x[NK+1:NK+N2,:]-x[NK:NK+N2-1,:]\n",
    "        dy=y[NK+1:NK+N2,:]-y[NK:NK+N2-1,:]\n",
    "        k1,k2=self.get_jifen(pr[NK+1:NK+N2,:],pi[NK+1:NK+N2,:],dx,dy)\n",
    "        k3,k4=self.get_jifen(qr[NK+1:NK+N2,:],qi[NK+1:NK+N2,:],dx,dy)    \n",
    "        k5,k6=self.get_jifen(rr[NK+1:NK+N2,:],ri[NK+1:NK+N2,:],dx,dy)\n",
    "        k7,k8=self.get_jifen(sr[NK+1:NK+N2,:],si[NK+1:NK+N2,:],dx,dy)  \n",
    "        loss_prd2 =tf.square(tf.reduce_sum(k1))+tf.square(tf.reduce_sum(k2))\\\n",
    "        +tf.square(tf.reduce_sum(k3))+tf.square(tf.reduce_sum(k4))\\\n",
    "        +tf.square(tf.reduce_sum(k5))+tf.square(tf.reduce_sum(k6))\\\n",
    "        +tf.square(tf.reduce_sum(k7))+tf.square(tf.reduce_sum(k8))      \n",
    "        \n",
    "        ######################################################################\n",
    "        ########## l_BC: Boundary condition loss\n",
    "        N2=10000\n",
    "        NK=2000\n",
    "        dx2=x[NK+1:NK+N2,:]-x[NK:NK+N2-1,:]\n",
    "        dy2=y[NK+1:NK+N2,:]-y[NK:NK+N2-1,:]\n",
    "        x2=x[NK:NK+N2-1,:]\n",
    "        y2=y[NK:NK+N2-1,:]\n",
    "        vecp1r,vecp1i,vecp2r,vecp2i=self.get_PP(x2,y2)   ### p(alpha)\n",
    "        loss_prd3=0\n",
    "        f1r,f1i,f2r,f2i=self.get_fplus(x2,y2,inv_pr[NK:NK+N2-1,:],inv_pi[NK:NK+N2-1,:],inv_qr[NK:NK+N2-1,:],inv_qi[NK:NK+N2-1,:],\\\n",
    "                                             inv_rr[NK:NK+N2-1,:],inv_ri[NK:NK+N2-1,:],inv_sr[NK:NK+N2-1,:],inv_si[NK:NK+N2-1,:],\\\n",
    "                                             kpr,kpi,kqr,kqi,krr,kri,ksr,ksi,\\\n",
    "                                             kvecp1r,kvecp1i,kvecp2r,kvecp2i,\\\n",
    "                                             vecp1r,vecp1i,vecp2r,vecp2i)\n",
    "        for ii in range(0,400,2):\n",
    "            if ii<400:\n",
    "                zz=ii*0.1\n",
    "            else:\n",
    "                zz=40+(ii-400)*1.0\n",
    "            f1rz,f1iz,f2rz,f2iz=self.get_fexp_plus2(x2,y2,f1r,f1i,f2r,f2i,zz)\n",
    "            kk1,kk2=self.get_jifen(f1rz,f1iz,dx2,dy2)\n",
    "            kk3,kk4=self.get_jifen(f2rz,f2iz,dx2,dy2)\n",
    "            loss_prd3 =loss_prd3+tf.square(tf.reduce_sum(kk1))+tf.square(tf.reduce_sum(kk2))\\\n",
    "            +tf.square(tf.reduce_sum(kk3))+tf.square(tf.reduce_sum(kk4))  \n",
    "\n",
    "        loss_prd = loss_prd2*10000+loss_prd3*100\n",
    "        return loss_prd\n",
    "\n",
    "    \n",
    "    ########## L_CI and L_BC in the upper half-plane\n",
    "    ########## l_CI: Caucy integral loss\n",
    "    ########## l_BC: Boundary condition loss\n",
    "    def loss_circle_neg(self, x, y, prt,pit,qrt,qit,rrt,rit,srt,sit):\n",
    "        pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8 = self.PDE(x, y)  ### G(alpha)\n",
    "        xx_kminus=np.ones([1,1])*(-2.5)\n",
    "        yy_kminus=np.ones([1,1])*(-0.0050)\n",
    "        kpr,kpi,kqr,kqi,krr,kri,ksr,ksi,\\\n",
    "               kpr2,kpi2,kqr2,kqi2,krr2,kri2,ksr2,ksi2,\\\n",
    "               kgv1,kgv2,kgv3,kgv4,kgv5,kgv6,kgv7,kgv8,\\\n",
    "               kgh1,kgh2,kgh3,kgh4,kgh5,kgh6,kgh7,kgh8 = self.PDE(xx_kminus, yy_kminus)  ### G+^-1(-k0)\n",
    "        kvecp1r,kvecp1i,kvecp2r,kvecp2i=self.get_PP(-2.5, -0.0050)   ### p(-k0)\n",
    "        ######################################################################\n",
    "        ########## l_CI: Caucy integral loss\n",
    "        N2=2000\n",
    "        NK=0\n",
    "        dx=x[NK+1:NK+N2,:]-x[NK:NK+N2-1,:]\n",
    "        dy=y[NK+1:NK+N2,:]-y[NK:NK+N2-1,:]\n",
    "        k1,k2=self.get_jifen(pr2[NK+1:NK+N2,:],pi2[NK+1:NK+N2,:],dx,dy)\n",
    "        k3,k4=self.get_jifen(qr2[NK+1:NK+N2,:],qi2[NK+1:NK+N2,:],dx,dy)    \n",
    "        k5,k6=self.get_jifen(rr2[NK+1:NK+N2,:],ri2[NK+1:NK+N2,:],dx,dy)\n",
    "        k7,k8=self.get_jifen(sr2[NK+1:NK+N2,:],si2[NK+1:NK+N2,:],dx,dy)   \n",
    "        loss_prd2 =tf.square(tf.reduce_sum(k1))+tf.square(tf.reduce_sum(k2))\\\n",
    "        +tf.square(tf.reduce_sum(k3))+tf.square(tf.reduce_sum(k4))\\\n",
    "        +tf.square(tf.reduce_sum(k5))+tf.square(tf.reduce_sum(k6))\\\n",
    "        +tf.square(tf.reduce_sum(k7))+tf.square(tf.reduce_sum(k8))\n",
    "        N2=10000\n",
    "        NK=2000\n",
    "        loss_prd3=0\n",
    "        dx2=x[NK+1:NK+N2,:]-x[NK:NK+N2-1,:]\n",
    "        dy2=y[NK+1:NK+N2,:]-y[NK:NK+N2-1,:]\n",
    "        x2=x[NK:NK+N2-1,:]\n",
    "        y2=y[NK:NK+N2-1,:]\n",
    "        inv_pr2,inv_pi2,inv_qr2,inv_qi2,inv_rr2,inv_ri2,inv_sr2,inv_si2=\\\n",
    "         self.get_inv(pr2[NK:NK+N2-1,:],pi2[NK:NK+N2-1,:],qr2[NK:NK+N2-1,:],qi2[NK:NK+N2-1,:],rr2[NK:NK+N2-1,:],ri2[NK:NK+N2-1,:],sr2[NK:NK+N2-1,:],si2[NK:NK+N2-1,:]) ### G-^-1(alpha)\n",
    "        f1r,f1i,f2r,f2i=self.get_fneg(x2,y2,inv_pr2,inv_pi2,inv_qr2,inv_qi2,inv_rr2,inv_ri2,inv_sr2,inv_si2,\\\n",
    "                                         kpr,kpi,kqr,kqi,krr,kri,ksr,ksi,\\\n",
    "                                         kvecp1r,kvecp1i,kvecp2r,kvecp2i)\n",
    "        ######################################################################\n",
    "        ########## l_BC: Boundary condition loss\n",
    "        for ii in range(0,400,2):\n",
    "            if ii<400:\n",
    "                zz=-ii*0.1\n",
    "            else:\n",
    "                zz=-40-(ii-400)*1.0                \n",
    "            f1rz,f1iz,f2rz,f2iz=self.get_fexp_neg2(x2,y2,f1r,f1i,f2r,f2i,zz)\n",
    "            kk1,kk2=self.get_jifen(f1rz,f1iz,dx2,dy2)\n",
    "            kk3,kk4=self.get_jifen(f2rz,f2iz,dx2,dy2) \n",
    "            loss_prd3 =loss_prd3+tf.square(tf.reduce_sum(kk1))+tf.square(tf.reduce_sum(kk2))\\\n",
    "            +tf.square(tf.reduce_sum(kk3))+tf.square(tf.reduce_sum(kk4))  \n",
    "        loss_prd = loss_prd2*10000+loss_prd3*100\n",
    "        return loss_prd\n",
    "\n",
    "    ########## L_CR in the whole complex \\alpha plane\n",
    "    def loss_pde_plus(self, x, y, prt,pit,qrt,qit,rrt,rit,srt,sit):\n",
    "        pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8 = self.PDE(x, y)\n",
    "\n",
    "        loss_prd3 =tf.reduce_mean(tf.square(gv1))+tf.reduce_mean(tf.square(gv2))\\\n",
    "        +tf.reduce_mean(tf.square(gv3))+tf.reduce_mean(tf.square(gv4))\\\n",
    "        +tf.reduce_mean(tf.square(gv5))+tf.reduce_mean(tf.square(gv6))\\\n",
    "        +tf.reduce_mean(tf.square(gv7))+tf.reduce_mean(tf.square(gv8))\n",
    "        loss_prd = loss_prd3\n",
    "        return loss_prd\n",
    "    \n",
    "    ########## Just neglect it\n",
    "    def loss_pde_neg(self, x, y, prt,pit,qrt,qit,rrt,rit,srt,sit):\n",
    "        pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8 = self.PDE(x, y)\n",
    "\n",
    "        loss_prd3 =tf.reduce_mean(tf.square(gh1))+tf.reduce_mean(tf.square(gh2))\\\n",
    "        +tf.reduce_mean(tf.square(gh3))+tf.reduce_mean(tf.square(gh4))\n",
    "\n",
    "        loss_prd = loss_prd3\n",
    "        return loss_prd\n",
    "    \n",
    "    ########## L_V in the splice region, the lower bound is 0.2\n",
    "    def loss_pde_junc(self, x, y, prt,pit,qrt,qit,rrt,rit,srt,sit):\n",
    "        pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8 = self.PDE(x, y)\n",
    "        \n",
    "        loss_prd3=tf.nn.relu(-tf.reduce_mean(tf.sqrt(tf.square(pr)+tf.square(pi)))+0.2)\\\n",
    "        +tf.nn.relu(-tf.reduce_mean(tf.sqrt(tf.square(qr)+tf.square(qi)))+0.2)\\\n",
    "        +tf.nn.relu(-tf.reduce_mean(tf.sqrt(tf.square(rr)+tf.square(ri)))+0.2)\\\n",
    "        +tf.nn.relu(-tf.reduce_mean(tf.sqrt(tf.square(sr)+tf.square(si)))+0.2)\n",
    "        loss_prd4 =tf.reduce_mean(tf.square(gv1))+tf.reduce_mean(tf.square(gv2))\\\n",
    "        +tf.reduce_mean(tf.square(gv3))+tf.reduce_mean(tf.square(gv4))\\\n",
    "        +tf.reduce_mean(tf.square(gv5))+tf.reduce_mean(tf.square(gv6))\\\n",
    "        +tf.reduce_mean(tf.square(gv7))+tf.reduce_mean(tf.square(gv8))\n",
    "        loss_prd = tf.square(loss_prd3/0.2)*100+loss_prd4\n",
    "        return loss_prd    \n",
    "    \n",
    "    @tf.function\n",
    "    def loss_glb(self, \n",
    "                 x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus,x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,\n",
    "                x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg,\n",
    "                x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc,ww1,ww2):\n",
    "        loss_plus   =  self.loss_pde_plus(x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus)\n",
    "#         loss_neg   =  self.loss_pde_neg(x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg)\n",
    "        loss_junc   = self.loss_pde_junc(x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc)\n",
    "        loss_neg=loss_junc\n",
    "        loss_circle_plus   =  self.loss_circle_plus(x_circle_plus, y_circle_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus)\n",
    "        loss_circle_neg   =  self.loss_circle_neg(x_circle_neg, y_circle_neg, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus)\n",
    "        loss= (loss_plus*self.w_k +loss_junc*self.w_k)+(loss_circle_plus*self.w_cr+loss_circle_neg*self.w_cr)\n",
    "        return loss,loss_plus,loss_neg,loss_junc,loss_circle_plus,loss_circle_neg\n",
    "\n",
    "    def loss_grad(self, \n",
    "                 x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus,x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,\n",
    "                x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg,\n",
    "                x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc,ww1,ww2): \n",
    "        with tf.GradientTape(persistent = True) as tp:\n",
    "            loss,loss_plus,loss_neg,loss_junc,loss_circle_plus,loss_circle_neg = self.loss_glb(x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus,\n",
    "                                                              x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,\n",
    "                x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg,\n",
    "                x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc,ww1,ww2)\n",
    "        grad = tp.gradient(loss, self.params)\n",
    "        del tp\n",
    "        return loss,loss_plus,loss_neg,loss_junc,loss_circle_plus,loss_circle_neg,grad\n",
    "    \n",
    "    @tf.function\n",
    "    def grad_desc(self, \n",
    "                 x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus,x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,\n",
    "                x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg,\n",
    "                x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc,ww1,ww2):\n",
    "        loss,loss_plus,loss_neg,loss_junc, loss_circle_plus,loss_circle_neg,grad = self.loss_grad(x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus,\n",
    "                                                                 x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,\n",
    "                x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg,\n",
    "                x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc,ww1,ww2)\n",
    "        self.optimizer.apply_gradients(zip(grad, self.params))\n",
    "        return loss,loss_plus,loss_neg,loss_junc,loss_circle_plus,loss_circle_neg\n",
    "        \n",
    "    def train(self, epoch = 10 ** 5, batch = 2 ** 6, tol = 1e-5): \n",
    "        print(\">>>>> training setting;\")\n",
    "        print(\"         # of epoch     :\", epoch)\n",
    "        print(\"         batch size     :\", batch)\n",
    "        print(\"         convergence tol:\", tol)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        x_plus = self.x_plus.numpy(); y_plus = self.y_plus.numpy()\n",
    "        prt_plus = self.prt_plus.numpy();pit_plus = self.pit_plus.numpy()\n",
    "        qrt_plus = self.qrt_plus.numpy();qit_plus = self.qit_plus.numpy()\n",
    "        rrt_plus = self.rrt_plus.numpy();rit_plus = self.rit_plus.numpy()\n",
    "        srt_plus = self.srt_plus.numpy();sit_plus = self.sit_plus.numpy()\n",
    "        x_neg = self.x_neg.numpy(); y_neg = self.y_neg.numpy()\n",
    "        prt_neg = self.prt_neg.numpy();pit_neg = self.pit_neg.numpy()\n",
    "        qrt_neg = self.qrt_neg.numpy();qit_neg = self.qit_neg.numpy()\n",
    "        rrt_neg = self.rrt_neg.numpy();rit_neg = self.rit_neg.numpy()\n",
    "        srt_neg = self.srt_neg.numpy();sit_neg = self.sit_neg.numpy()\n",
    "        x_junc = self.x_junc.numpy(); y_junc = self.y_junc.numpy()\n",
    "        prt_junc = self.prt_junc.numpy();pit_junc = self.pit_junc.numpy()\n",
    "        qrt_junc = self.qrt_junc.numpy();qit_junc = self.qit_junc.numpy()\n",
    "        rrt_junc = self.rrt_junc.numpy();rit_junc = self.rit_junc.numpy()\n",
    "        srt_junc = self.srt_junc.numpy();sit_junc = self.sit_junc.numpy()\n",
    "        ww1=1\n",
    "        ww2=1\n",
    "        for ep in range(epoch):\n",
    "            ep_loss = 0\n",
    "            ep_loss_plus = 0\n",
    "            ep_loss_neg = 0\n",
    "            ep_loss_junc = 0\n",
    "                \n",
    "            if batch == 0:   # full-batch training\n",
    "                ep_loss = self.grad_desc(x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus,x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,\n",
    "                x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg,\n",
    "                x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc)\n",
    "            \n",
    "            else:   # mini-batch training\n",
    "                n_plus = self.x_plus.shape[0]; idx_plus = np.random.permutation(n_plus)\n",
    "                n_neg = self.x_neg.shape[0]; idx_neg = np.random.permutation(n_neg)\n",
    "                n_junc = self.x_junc.shape[0]; idx_junc = np.random.permutation(n_junc)\n",
    "\n",
    "                n_data = self.x_plus.shape[0] + self.x_neg.shape[0] + self.x_junc.shape[0]\n",
    "                shf_idx = np.random.permutation(n_data)\n",
    "                \n",
    "                for idx in range(0, n_junc, batch):\n",
    "                    # batch for R+\n",
    "                    \n",
    "                    x_plus_btch = tf.convert_to_tensor(x_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "                    y_plus_btch = tf.convert_to_tensor(y_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "                    prt_plus_btch = tf.convert_to_tensor(prt_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "                    pit_plus_btch = tf.convert_to_tensor(pit_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "                    qrt_plus_btch = tf.convert_to_tensor(qrt_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "                    qit_plus_btch = tf.convert_to_tensor(qit_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "                    rrt_plus_btch = tf.convert_to_tensor(rrt_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "                    rit_plus_btch = tf.convert_to_tensor(rit_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "                    srt_plus_btch = tf.convert_to_tensor(srt_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "                    sit_plus_btch = tf.convert_to_tensor(sit_plus[idx_plus[idx: idx + batch if idx + batch < n_plus else n_plus]], dtype = self.data_type)\n",
    "\n",
    "\n",
    "                    x_neg_btch = x_plus_btch\n",
    "                    y_neg_btch = x_plus_btch\n",
    "                    prt_neg_btch = x_plus_btch\n",
    "                    pit_neg_btch = x_plus_btch\n",
    "                    qrt_neg_btch = x_plus_btch\n",
    "                    qit_neg_btch = x_plus_btch\n",
    "                    rrt_neg_btch = x_plus_btch\n",
    "                    rit_neg_btch = x_plus_btch\n",
    "                    srt_neg_btch = x_plus_btch\n",
    "                    sit_neg_btch = x_plus_btch\n",
    "\n",
    "                    x_junc_btch = tf.convert_to_tensor(x_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "                    y_junc_btch = tf.convert_to_tensor(y_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "                    prt_junc_btch = tf.convert_to_tensor(prt_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "                    pit_junc_btch = tf.convert_to_tensor(pit_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "                    qrt_junc_btch = tf.convert_to_tensor(qrt_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "                    qit_junc_btch = tf.convert_to_tensor(qit_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "                    rrt_junc_btch = tf.convert_to_tensor(rrt_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "                    rit_junc_btch = tf.convert_to_tensor(rit_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "                    srt_junc_btch = tf.convert_to_tensor(srt_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "                    sit_junc_btch = tf.convert_to_tensor(sit_junc[idx_junc[idx: idx + batch if idx + batch < n_junc else n_junc]], dtype = self.data_type)\n",
    "\n",
    " \n",
    "                                         \n",
    "                    # compute loss and perform gradient descent\n",
    "                    loss_btch,loss_plus_btch,loss_neg_btch,loss_junc_btch ,loss_circle_plus,loss_circle_neg= self.grad_desc(x_plus_btch, y_plus_btch, prt_plus_btch,pit_plus_btch,qrt_plus_btch,qit_plus_btch,rrt_plus_btch,rit_plus_btch,srt_plus_btch,sit_plus_btch,\n",
    "                         x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,                                                                  \n",
    "                         x_neg_btch, y_neg_btch, prt_neg_btch,pit_neg_btch,qrt_neg_btch,qit_neg_btch,rrt_neg_btch,rit_neg_btch,srt_neg_btch,sit_neg_btch,\n",
    "                         x_junc_btch, y_junc_btch, prt_junc_btch,pit_junc_btch,qrt_junc_btch,qit_junc_btch,rrt_junc_btch,rit_junc_btch,srt_junc_btch,sit_junc_btch,ww1,ww2)\n",
    "                    ep_loss += loss_btch / int(n_junc / batch)\n",
    "                    ep_loss_plus += loss_plus_btch / int(n_junc / batch)\n",
    "                    ep_loss_junc += loss_junc_btch / int(n_junc / batch)\n",
    "                    ep_loss_neg += loss_neg_btch / int(n_junc / batch)\n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "            if ep % self.f_mntr == 0:\n",
    "                \n",
    "                elps = time.time() - t0\n",
    "                \n",
    "                self.ep_log.append(ep)\n",
    "                self.loss_log.append(ep_loss)\n",
    "                print(\"ep: %d, loss: %.3e, elps: %.3f, loss_plus:%.3e, loss_neg:%.3e, loss_junc:%.3e, loss_circle_plus:%.3e,loss_circle_neg:%.3e,\" % (ep, ep_loss, elps,ep_loss_plus,ep_loss_neg,ep_loss_junc,\n",
    "                                                                                                        loss_circle_plus,loss_circle_neg))\n",
    "                t0 = time.time()\n",
    "            \n",
    "            if ep_loss < tol:\n",
    "                print(\">>>>> program terminating with the loss converging to its tolerance.\")\n",
    "                print(\"\\n************************************************************\")\n",
    "                print(\"*****************     MAIN PROGRAM END     *****************\")\n",
    "                print(\"************************************************************\")\n",
    "                print(\">>>>> end time:\", datetime.datetime.now())\n",
    "                break\n",
    "        \n",
    "        print(\"\\n************************************************************\")\n",
    "        print(\"*****************     MAIN PROGRAM END     *****************\")\n",
    "        print(\"************************************************************\")\n",
    "        print(\">>>>> end time:\", datetime.datetime.now())\n",
    "                \n",
    "    def predict(self, x, y):\n",
    "        pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8 = self.PDE(x,y)\n",
    "        return pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8\n",
    "    def save_weight(self,h5_name):\n",
    "        self.dnn.save_weights(h5_name)\n",
    "    def load_weight(self,h5_name):\n",
    "        self.dnn.load_weights(h5_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# network structure\n",
    "in_dim  = 2\n",
    "out_dim = 8\n",
    "width = 2 ** 9   \n",
    "depth = 5\n",
    "\n",
    "# training setting\n",
    "n_epch = int(3e4)\n",
    "n_btch = int(2 ** 12)# 2**12=4096\n",
    "c_tol  = 1e-8\n",
    "\n",
    "# dataset prep\n",
    "N_neg = int(2e4)   # evaluates R-\n",
    "N_plus = int(2e4)   # evaluates R+\n",
    "N_junc = int(2e4)   # evaluates R_junction\n",
    "\n",
    "# optimization\n",
    "w_init = \"Glorot\"\n",
    "b_init = \"zeros\"\n",
    "act = \"selu\"\n",
    "lr0 = 5e-2\n",
    "gam = 1e-2\n",
    "lrd_exp = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = lr0, \n",
    "    decay_steps = n_epch, \n",
    "    decay_rate = gam, \n",
    "    staircase = False\n",
    "    )\n",
    "lr = lrd_exp   # 1e-3 / lrd_exp / lrd_cos\n",
    "opt = \"Adam\"\n",
    "f_scl = \"minmax\"\n",
    "laaf = False\n",
    "\n",
    "# system param\n",
    "# rho = 1.\n",
    "# nu  = .01\n",
    "\n",
    "# weight\n",
    "w_plus = 1.\n",
    "w_neg = 1.\n",
    "w_junc = 1.\n",
    "\n",
    "# rarely change\n",
    "f_mntr = 10\n",
    "r_seed = 1234\n",
    "\n",
    "def params():\n",
    "    print(\"python    :\", sys.version)\n",
    "    print(\"tensorflow:\", tf.__version__)\n",
    "    print(\"rand seed :\", r_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(r_seed)\n",
    "    np.random.seed(r_seed)\n",
    "    tf.random.set_seed(r_seed)\n",
    "\n",
    "    return in_dim, out_dim, width, depth, \\\n",
    "        w_init, b_init, act, \\\n",
    "        lr, opt, \\\n",
    "        f_scl, laaf, \\\n",
    "        w_plus, w_neg, w_junc,\\\n",
    "        f_mntr, r_seed, \\\n",
    "        n_epch, n_btch, c_tol, \\\n",
    "        N_plus, N_neg, N_junc\n",
    "config_gpu(gpu_flg = 1)\n",
    "in_dim, out_dim, width, depth, \\\n",
    "        w_init, b_init, act, \\\n",
    "        lr, opt, \\\n",
    "        f_scl, laaf, \\\n",
    "        w_plus, w_neg, w_junc,\\\n",
    "        f_mntr, r_seed, \\\n",
    "        n_epch, n_btch, c_tol, \\\n",
    "        N_plus, N_neg, N_junc=params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1=50000  # training data size in range 1 real range(-20,20), imaginary range(-6,6)\n",
    "N2=30000  # training data size in range 2 real range(-50,50), imaginary range(-50,50)\n",
    "\n",
    "###### load PQVR_V8.mat that include the integral path\n",
    "AN=scio.loadmat('PQVR_V8.mat')\n",
    "x_circle_plus=tf.convert_to_tensor(AN['x_circle_plus'],dtype=tf.float32)\n",
    "y_circle_plus=tf.convert_to_tensor(AN['y_circle_plus'],dtype=tf.float32)\n",
    "x_circle_neg=tf.convert_to_tensor(AN['x_circle_neg'],dtype=tf.float32)\n",
    "y_circle_neg=tf.convert_to_tensor(AN['y_circle_neg'],dtype=tf.float32)\n",
    "\n",
    "###### generate training data in the region 1: real range(-20,20), imaginary range(-6,6)\n",
    "x_plus1=(np.random.random([N1,1])-0.5)*40\n",
    "y_plus1=(np.random.random([N1,1])-0.5)*12\n",
    "x_junc1=(np.random.random([N1,1])-0.5)*40\n",
    "y_junc1=(np.random.random([N1,1])-0.5)*0.01 \n",
    "x_neg1=(np.random.random([N1,1])-0.5)*40\n",
    "y_neg1=(np.random.random([N1,1]))*(-20)-0.08\n",
    "\n",
    "###### generate training data in the region 2: real range(-50,50), imaginary range(-50,50)\n",
    "x_plus2=(np.random.random([N2,1])-0.5)*100\n",
    "y_plus2=(np.random.random([N2,1])-0.5)*100\n",
    "x_junc2=(np.random.random([N2,1])-0.5)*40\n",
    "y_junc2=(np.random.random([N2,1])-0.5)*0.01\n",
    "x_neg2=(np.random.random([N2,1])-0.5)*100\n",
    "y_neg2=(np.random.random([N2,1]))*(-20)-0.08\n",
    "\n",
    "x_plus=np.append(x_plus1,x_plus2,axis=0)\n",
    "y_plus=np.append(y_plus1,y_plus2,axis=0)\n",
    "x_junc=np.append(x_junc1,x_junc2,axis=0)\n",
    "y_junc=np.append(y_junc1,y_junc2,axis=0)\n",
    "x_neg=np.append(x_neg1,x_neg2,axis=0)\n",
    "y_neg=np.append(y_neg1,y_neg2,axis=0)\n",
    "\n",
    "def getp(w1,w2):\n",
    "    x=tf.complex([w1],[w2])\n",
    "    k=tf.complex([5.0],[0.01])\n",
    "    gamma=tf.sqrt(tf.square(x)-tf.square(k))\n",
    "    z=-gamma/2*0+1\n",
    "    xr=tf.compat.v1.real(z)\n",
    "    xi=tf.compat.v1.imag(z)\n",
    "    return xr,xi  \n",
    "def getq(w1,w2):\n",
    "    x=tf.complex([w1],[w2])\n",
    "    k=tf.complex([5.0],[0.01])\n",
    "    gamma=tf.sqrt(tf.square(x)-tf.square(k))\n",
    "    j0=tf.complex([0.0],[1.0])\n",
    "    a=tf.complex([0.0],[0.0])\n",
    "    h=tf.complex([2.0],[0.0])\n",
    "    gammaj=j0*tf.sqrt(tf.square(x)-tf.square(k))\n",
    "    gamma_neg=tf.sqrt(k-x)\n",
    "    gamma_plus=gammaj/gamma_neg\n",
    "\n",
    "    z=gamma_neg/gamma_plus*tf.exp(-h*gamma)\n",
    "    xr=tf.compat.v1.real(z)\n",
    "    xi=tf.compat.v1.imag(z)\n",
    "    return xr,xi      \n",
    "def getr(w1,w2):\n",
    "    x=tf.complex([w1],[w2])\n",
    "    k=tf.complex([5.0],[0.01])\n",
    "    gamma=tf.sqrt(tf.square(x)-tf.square(k))\n",
    "    j0=tf.complex([0.0],[1.0])\n",
    "    a=tf.complex([0.0],[0.0])\n",
    "    h=tf.complex([2.0],[0.0])\n",
    "    gammaj=j0*tf.sqrt(tf.square(x)-tf.square(k))\n",
    "    gamma_neg=tf.sqrt(k-x)\n",
    "    gamma_plus=gammaj/gamma_neg\n",
    "#         gamma=gamma_plus*gamma_neg\n",
    "    z=-gamma_plus/gamma_neg*tf.exp(-h*gamma)\n",
    "    xr=tf.compat.v1.real(z)\n",
    "    xi=tf.compat.v1.imag(z)\n",
    "    return xr,xi     \n",
    "def gets(w1,w2):\n",
    "    x=tf.complex([w1],[w2])\n",
    "    k=tf.complex([5.0],[0.01])\n",
    "    gamma=tf.sqrt(tf.square(x)-tf.square(k))\n",
    "    z=-gamma/2*0+1\n",
    "    xr=tf.compat.v1.real(z)\n",
    "    xi=tf.compat.v1.imag(z)\n",
    "    return xr,xi \n",
    "x_plus=tf.convert_to_tensor(x_plus,dtype=tf.float32)\n",
    "y_plus=tf.convert_to_tensor(y_plus,dtype=tf.float32)\n",
    "prt_plus,pit_plus=getp(x_plus,y_plus)\n",
    "qrt_plus,qit_plus=getq(x_plus,y_plus)\n",
    "rrt_plus,rit_plus=getr(x_plus,y_plus)\n",
    "srt_plus,sit_plus=gets(x_plus,y_plus)\n",
    "prt_plus=prt_plus[0];pit_plus=pit_plus[0];qrt_plus=qrt_plus[0];qit_plus=qit_plus[0];\n",
    "rrt_plus=rrt_plus[0];rit_plus=rit_plus[0];srt_plus=srt_plus[0];sit_plus=sit_plus[0];\n",
    "x_junc=tf.convert_to_tensor(x_junc,dtype=tf.float32)\n",
    "y_junc=tf.convert_to_tensor(y_junc,dtype=tf.float32)\n",
    "prt_junc,pit_junc=getp(x_junc,y_junc)\n",
    "qrt_junc,qit_junc=getq(x_junc,y_junc)\n",
    "rrt_junc,rit_junc=getr(x_junc,y_junc)\n",
    "srt_junc,sit_junc=gets(x_junc,y_junc)\n",
    "prt_junc=prt_junc[0];pit_junc=pit_junc[0];qrt_junc=qrt_junc[0];qit_junc=qit_junc[0];\n",
    "rrt_junc=rrt_junc[0];rit_junc=rit_junc[0];srt_junc=srt_junc[0];sit_junc=sit_junc[0];\n",
    "x_neg=tf.convert_to_tensor(x_neg,dtype=tf.float32)\n",
    "y_neg=tf.convert_to_tensor(y_neg,dtype=tf.float32)\n",
    "prt_neg,pit_neg=getp(x_neg,y_neg)\n",
    "qrt_neg,qit_neg=getq(x_neg,y_neg)\n",
    "rrt_neg,rit_neg=getr(x_neg,y_neg)\n",
    "srt_neg,sit_neg=gets(x_neg,y_neg)\n",
    "prt_neg=prt_neg[0];pit_neg=pit_neg[0];qrt_neg=qrt_neg[0];qit_neg=qit_neg[0];\n",
    "rrt_neg=rrt_neg[0];rit_neg=rit_neg[0];srt_neg=srt_neg[0];sit_neg=sit_neg[0];\n",
    "\n",
    "x_circle_neg=tf.convert_to_tensor(x_circle_neg,dtype=tf.float32)\n",
    "y_circle_neg=tf.convert_to_tensor(y_circle_neg,dtype=tf.float32)\n",
    "x_circle_plus=tf.convert_to_tensor(x_circle_plus,dtype=tf.float32)\n",
    "y_circle_plus=tf.convert_to_tensor(y_circle_plus,dtype=tf.float32)\n",
    "# print((qrt_plus))\n",
    "plt.scatter(x_plus,rit_plus)\n",
    "meanp,vp=tf.nn.moments(pit_junc,[0])\n",
    "# print(vp)\n",
    "plt.figure()\n",
    "plt.plot(x_circle_plus[0:2000],y_circle_plus[0:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "################## test\n",
    "width=512\n",
    "depth=6\n",
    "lr0=5e-3\n",
    "n_epch = int(3e4)\n",
    "gam=0.01\n",
    "lrd_exp = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = lr0, \n",
    "    decay_steps = n_epch, \n",
    "    decay_rate = gam, \n",
    "    staircase = False\n",
    "    )\n",
    "# lrd_cos = tf.keras.optimizers.schedules.CosineDecay(\n",
    "#     initial_learning_rate = lr0, \n",
    "#     decay_steps = n_epch, \n",
    "#     alpha = gam\n",
    "#     )\n",
    "\n",
    "minn = MINN_init(x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus,\n",
    "                x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg,\n",
    "                x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc,x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,\n",
    "             Rm = in_dim, Rn = out_dim, Rl = width, depth=depth, activ = 'relu', BN = False, \n",
    "             w_init = \"glorot_normal\", b_init = \"zero\", \n",
    "             lr =lrd_exp, opt = \"Adam\",  w_k = 100, w_cr = 1, w_z = 0.1,w_dense = 0.1,\n",
    "             f_mntr = 10, r_seed = 1234)\n",
    "# w_k loss_plus\n",
    "# w_cr loss_junc\n",
    "minn.load_weight('dnn28_mat_2factor.h5')\n",
    "\n",
    "# first train on mse to 5e-3\n",
    "# second train on mae to 1e-4\n",
    "\n",
    "n_btch = int(2 ** 14)# 2**13=8192\n",
    "c_tol  = 5e-6\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    minn.train(n_epch, n_btch, c_tol)\n",
    "# minn.save_weight('dnn1.h5')### lr=1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minn.save_weight('dnn1_mat_w5.h5')### train from:dnn28_mat_2factor2**14,5e-3=lrd_exp,,range(0,400,2),0:0.1:40,40:1:240,w_k=100,N1=50000 \n",
    "# minn.save_weight('dnn2_mat_w5.h5')### train from:dnn1_mat_w52**14,1e-4=lrd_exp,,range(0,600,2),0:0.1:40,40:1:240,w_k=100,N1=50000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the factorization result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## test\n",
    "width=512\n",
    "depth=6\n",
    "M=10000\n",
    "minn = MINN_init(x_plus, y_plus, prt_plus,pit_plus,qrt_plus,qit_plus,rrt_plus,rit_plus,srt_plus,sit_plus,\n",
    "                x_neg, y_neg, prt_neg,pit_neg,qrt_neg,qit_neg,rrt_neg,rit_neg,srt_neg,sit_neg,\n",
    "                x_junc, y_junc, prt_junc,pit_junc,qrt_junc,qit_junc,rrt_junc,rit_junc,srt_junc,sit_junc,x_circle_plus,y_circle_plus,x_circle_neg,y_circle_neg,\n",
    "             Rm = in_dim, Rn = out_dim, Rl = width, depth=depth, activ = 'relu', BN = False, \n",
    "             w_init = \"glorot_normal\", b_init = \"zero\", \n",
    "             lr = 1e-4, opt = \"Adam\",  w_k = 1., w_cr = 1., w_z = 1.,w_dense = 0.1,\n",
    "             f_mntr = 10, r_seed = 1235)\n",
    "minn.load_weight('dnn1_mat_w5.h5')\n",
    "\n",
    "pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8=minn.predict(x_junc[0:M,:], y_junc[0:M,:])\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# ax=plt.axes(projection=\"3d\")\n",
    "# # ax.scatter3D(x_neg[0:M,:],y_neg[0:M,:],si)\n",
    "\n",
    "# ax.scatter3D(x_neg[0:M,:],y_neg[0:M,:],si2)\n",
    "plt.scatter(x_junc[0:M,:],tf.sqrt(tf.square(pr)+tf.square(pi)))\n",
    "# plt.title('gv1')\n",
    "plt.figure()\n",
    "plt.scatter(x_junc[0:M,:],tf.sqrt(tf.square(sr)+tf.square(si)))\n",
    "plt.figure()\n",
    "plt.scatter(x_junc[0:M,:],tf.sqrt(tf.square(qr2)+tf.square(qi2)))\n",
    "# plt.scatter(x_plus,rrt_plus)\n",
    "plt.figure()\n",
    "plt.scatter(x_junc[0:M,:],tf.sqrt(tf.square(rr2)+tf.square(ri2)))\n",
    "# plt.scatter(x_plus,rit_plus)\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE TO MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### G_{+}^{-1}(\\alpha) on the integral path C\n",
    "AB=scio.loadmat('xy_pre.mat')\n",
    "x_test=AB['x_pre'];y_test=AB['y_pre']\n",
    "plt.plot(x_test,y_test)\n",
    "pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8=minn.predict(x_test, y_test)\n",
    "\n",
    "scio.savemat('G_mat w_5.mat',{'pr':pr.numpy(),'pi':pi.numpy(),'qr':qr.numpy(),'qi':qi.numpy(),'rr':rr.numpy(),'ri':ri.numpy()\n",
    "                     ,'sr':sr.numpy(),'si':si.numpy(),\n",
    "                     'pr2':pr2.numpy(),'pi2':pi2.numpy(),'qr2':qr2.numpy(),'qi2':qi2.numpy(),'rr2':rr2.numpy(),'ri2':ri2.numpy()\n",
    "                     ,'sr2':sr2.numpy(),'si2':si2.numpy()})\n",
    "AB=scio.loadmat('k0_pre.mat')\n",
    "x_test=AB['x_k0'];y_test=AB['y_k0']\n",
    "\n",
    "###### G_{+}^{-1}(-k0)\n",
    "pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "               pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "               gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "               gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8=minn.predict(x_test, y_test)\n",
    "\n",
    "scio.savemat('GK_mat w_5.mat',{'prk':pr.numpy(),'pik':pi.numpy(),'qrk':qr.numpy(),'qik':qi.numpy(),'rrk':rr.numpy(),'rik':ri.numpy()\n",
    "                     ,'srk':sr.numpy(),'sik':si.numpy()})\n",
    "print(y_test)\n",
    "\n",
    "# ###### G_{+}^{-1}(\\alpha) for zone 1 far-field result\n",
    "# AB=scio.loadmat('xy_pre_v1 w_5.mat')\n",
    "# x_test=AB['x_pre'];y_test=AB['y_pre']\n",
    "# # minn.load_weight('dnn3_first.h5')\n",
    "# plt.plot(x_test,y_test)\n",
    "# pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "#                pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "#                gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "#                gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8=minn.predict(x_test, y_test)\n",
    "\n",
    "# scio.savemat('Gkcos_mat1 w_5.mat',{'pr':pr.numpy(),'pi':pi.numpy(),'qr':qr.numpy(),'qi':qi.numpy(),'rr':rr.numpy(),'ri':ri.numpy()\n",
    "#                      ,'sr':sr.numpy(),'si':si.numpy(),\n",
    "#                      'pr2':pr2.numpy(),'pi2':pi2.numpy(),'qr2':qr2.numpy(),'qi2':qi2.numpy(),'rr2':rr2.numpy(),'ri2':ri2.numpy()\n",
    "#                      ,'sr2':sr2.numpy(),'si2':si2.numpy()})\n",
    "\n",
    "# ###### G_{+}^{-1}(\\alpha) for zone 3 far-field result\n",
    "# AB=scio.loadmat('xy_pre_v3 w_5.mat')\n",
    "# x_test=AB['x_pre'];y_test=AB['y_pre']\n",
    "# # minn.load_weight('dnn3_first.h5')\n",
    "# # plt.plot(x_test,y_test)\n",
    "# pr,pi,qr,qi,rr,ri,sr,si,\\\n",
    "#                pr2,pi2,qr2,qi2,rr2,ri2,sr2,si2,\\\n",
    "#                gv1,gv2,gv3,gv4,gv5,gv6,gv7,gv8,\\\n",
    "#                gh1,gh2,gh3,gh4,gh5,gh6,gh7,gh8=minn.predict(x_test, y_test)\n",
    "\n",
    "# scio.savemat('Gkcos_mat3 w_5.mat',{'pr':pr.numpy(),'pi':pi.numpy(),'qr':qr.numpy(),'qi':qi.numpy(),'rr':rr.numpy(),'ri':ri.numpy()\n",
    "#                      ,'sr':sr.numpy(),'si':si.numpy(),\n",
    "#                      'pr2':pr2.numpy(),'pi2':pi2.numpy(),'qr2':qr2.numpy(),'qi2':qi2.numpy(),'rr2':rr2.numpy(),'ri2':ri2.numpy()\n",
    "#                      ,'sr2':sr2.numpy(),'si2':si2.numpy()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftf",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
